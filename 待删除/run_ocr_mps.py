#!/usr/bin/env python3
"""
DeepSeek-OCR æ–‡æ¡£è½¬æ¢æµ‹è¯•è„šæœ¬ï¼ˆMPS ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
ç”¨äºæµ‹è¯•å›¾ç‰‡OCRè¯†åˆ«å¹¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ - ä¸“é—¨é’ˆå¯¹ macOS MPS
"""

import os
import sys
from pathlib import Path
import torch

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_dir = Path(__file__).parent / "DeepSeek-OCR"
if project_dir.exists():
    sys.path.insert(0, str(project_dir))

print("=" * 60)
print("DeepSeek-OCR æ–‡æ¡£è½¬æ¢æµ‹è¯• (MPS ç‰ˆæœ¬)")
print("=" * 60)
print()

# æ£€æŸ¥ç¯å¢ƒ
try:
    print(f"âœ“ PyTorch ç‰ˆæœ¬: {torch.__version__}")

    if torch.backends.mps.is_available():
        print("âœ“ MPS (Metal Performance Shaders) å¯ç”¨")
        device = "mps"
    else:
        print("âš  MPS ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPU")
        device = "cpu"
    print()
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿å·²æ¿€æ´» conda ç¯å¢ƒ: conda activate deepseek-ocr")
    sys.exit(1)

# é…ç½®ç¯å¢ƒå˜é‡
os.environ["PYTORCH_MPS_HIGH_WATERMARK_RATIO"] = "0.0"

# æ£€æŸ¥å›¾ç‰‡
test_image_dir = Path(__file__).parent / "test_images"
if not test_image_dir.exists():
    test_image_dir.mkdir(parents=True)
    print(f"âš  æµ‹è¯•å›¾ç‰‡ç›®å½•å·²åˆ›å»º: {test_image_dir}")
    print("è¯·å°†æµ‹è¯•å›¾ç‰‡æ”¾å…¥è¯¥ç›®å½•")
    sys.exit(0)

# æŸ¥æ‰¾æµ‹è¯•å›¾ç‰‡
image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.webp']
test_images = []
for ext in image_extensions:
    test_images.extend(test_image_dir.glob(f"*{ext}"))

if not test_images:
    print(f"âŒ åœ¨ {test_image_dir} ä¸­æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
    print(f"æ”¯æŒçš„æ ¼å¼: {', '.join(image_extensions)}")
    sys.exit(1)

print(f"æ‰¾åˆ° {len(test_images)} å¼ æµ‹è¯•å›¾ç‰‡:")
for img in test_images:
    print(f"  - {img.name}")
print()

# åŠ è½½æ¨¡å‹
print("æ­£åœ¨åŠ è½½ DeepSeek-OCR æ¨¡å‹...")
print("(é¦–æ¬¡è¿è¡Œä¼šä» Hugging Face ä¸‹è½½æ¨¡å‹ï¼Œçº¦ 10GBï¼Œè¯·è€å¿ƒç­‰å¾…)")
print()

try:
    from transformers import AutoModel, AutoTokenizer
    from PIL import Image

    model_name = 'deepseek-ai/DeepSeek-OCR'

    print("åŠ è½½åˆ†è¯å™¨...")
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        trust_remote_code=True
    )

    print("åŠ è½½æ¨¡å‹...")
    model = AutoModel.from_pretrained(
        model_name,
        trust_remote_code=True,
        use_safetensors=True
    )

    # ä½¿ç”¨ bfloat16 å¹¶ç§»åŠ¨åˆ° MPS è®¾å¤‡
    print(f"å°†æ¨¡å‹ç§»åŠ¨åˆ° {device} è®¾å¤‡...")
    model = model.eval().to(torch.bfloat16).to(device)
    print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸï¼Œä½¿ç”¨è®¾å¤‡: {device}")
    print()

except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# åˆ›å»ºè¾“å‡ºç›®å½•
output_dir = Path(__file__).parent / "ocr_output"
output_dir.mkdir(exist_ok=True)

# å¤„ç†æ¯å¼ å›¾ç‰‡
print("=" * 60)
print("å¼€å§‹ OCR è¯†åˆ«...")
print("=" * 60)
print()

# ç”±äºåŸå§‹ infer æ–¹æ³•ç¡¬ç¼–ç äº† CUDAï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨æ›¿ä»£æ–¹æ³•
# ä½¿ç”¨ CPU/MPS å…¼å®¹çš„æ–¹å¼
print("âš  æ³¨æ„: ç”±äº DeepSeek-OCR å®˜æ–¹ä»£ç ç¡¬ç¼–ç äº† CUDA è®¾å¤‡ï¼Œ")
print("   åœ¨ macOS (MPS) ä¸Šéœ€è¦ä½¿ç”¨ CPU æ¨¡å¼æˆ–ä¿®æ”¹æºç ã€‚")
print()
print("ğŸ”„ å°è¯•ä½¿ç”¨ CPU æ¨¡å¼è¿›è¡Œæµ‹è¯•...")
print()

# é‡æ–°åŠ è½½æ¨¡å‹åˆ° CPU
try:
    print("é‡æ–°åŠ è½½æ¨¡å‹åˆ° CPU...")
    model = model.to("cpu")
    device = "cpu"
    print("âœ“ å·²åˆ‡æ¢åˆ° CPU æ¨¡å¼")
    print()

    for idx, image_file in enumerate(test_images, 1):
        print(f"[{idx}/{len(test_images)}] å¤„ç†: {image_file.name}")

        # å‡†å¤‡æç¤ºè¯ - æ–‡æ¡£è½¬æ¢ä¸º Markdown
        prompt = "<image>\n<|grounding|>Convert the document to markdown."

        # ä¸ºæ¯å¼ å›¾ç‰‡åˆ›å»ºå•ç‹¬çš„è¾“å‡ºç›®å½•
        img_output_dir = output_dir / image_file.stem
        img_output_dir.mkdir(exist_ok=True)

        try:
            # æ‰§è¡Œæ¨ç† - ä½¿ç”¨ CPU
            print("  æ­£åœ¨è¯†åˆ«ï¼ˆCPU æ¨¡å¼ï¼Œå¯èƒ½è¾ƒæ…¢ï¼‰...")

            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¿®æ”¹ infer è°ƒç”¨æˆ–ç›´æ¥è°ƒç”¨åº•å±‚æ–¹æ³•
            # ç”±äºåŸå§‹ä»£ç æœ‰ CUDA ä¾èµ–ï¼Œæˆ‘ä»¬å…ˆå°è¯•ç›´æ¥è°ƒç”¨
            result = model.infer(
                tokenizer,
                prompt=prompt,
                image_file=str(image_file),
                output_path=str(img_output_dir),
                base_size=1024,
                image_size=640,
                crop_mode=True,
                save_results=True,
                test_compress=True
            )

            # ä¿å­˜è¯†åˆ«ç»“æœåˆ°æ–‡æœ¬æ–‡ä»¶
            result_file = img_output_dir / f"{image_file.stem}_result.md"
            with open(result_file, 'w', encoding='utf-8') as f:
                f.write(f"# OCR è¯†åˆ«ç»“æœ\n\n")
                f.write(f"**åŸå§‹å›¾ç‰‡**: {image_file.name}\n\n")
                f.write(f"**è¯†åˆ«æ—¶é—´**: {__import__('datetime').datetime.now()}\n\n")
                f.write(f"**è®¾å¤‡**: {device}\n\n")
                f.write(f"---\n\n")
                if isinstance(result, str):
                    f.write(result)
                else:
                    f.write(str(result))

            print(f"  âœ“ è¯†åˆ«å®Œæˆ")
            print(f"  âœ“ ç»“æœå·²ä¿å­˜åˆ°: {img_output_dir}")
            print(f"  âœ“ Markdown æ–‡ä»¶: {result_file.name}")
            print()

        except Exception as e:
            print(f"  âŒ è¯†åˆ«å¤±è´¥: {e}")
            print()
            print("ğŸ’¡ æç¤º: DeepSeek-OCR æºç éœ€è¦ä¿®æ”¹ä»¥æ”¯æŒ macOS MPS")
            print("   è¯·å‚è€ƒä¸‹æ–¹çš„ä¿®å¤æ–¹æ¡ˆ")
            import traceback
            traceback.print_exc()
            print()
            break

except Exception as e:
    print(f"âŒ åˆ‡æ¢åˆ° CPU å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("=" * 60)
print("æµ‹è¯•ç»“æŸ")
print("=" * 60)
print()
print(f"è¾“å‡ºç›®å½•: {output_dir}")
print()
print("âš  å¦‚æœé‡åˆ° CUDA é”™è¯¯ï¼Œè¯·æŸ¥çœ‹ä¸‹æ–¹çš„ä¿®å¤æ–¹æ¡ˆ...")
print()
